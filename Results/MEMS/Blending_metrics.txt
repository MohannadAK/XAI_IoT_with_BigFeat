+-----------------------+-------------------------------------------------------+
| Metric                | Value                                                 |
+=======================+=======================================================+
| Accuracy              | 0.6853                                                |
+-----------------------+-------------------------------------------------------+
| Classification Report | precision    recall  f1-score   support               |
|                       |                                                       |
|                       |            1       0.68      0.77      0.72      3284 |
|                       |            2       0.77      0.78      0.77      1725 |
|                       |            3       0.55      0.40      0.46      1464 |
|                       |                                                       |
|                       |     accuracy                           0.69      6473 |
|                       |    macro avg       0.67      0.65      0.65      6473 |
|                       | weighted avg       0.68      0.69      0.68      6473 |
+-----------------------+-------------------------------------------------------+
| Confusion Matrix      | [[2514,  324,  446],                                  |
|                       |  [ 362, 1339,   24],                                  |
|                       |  [ 806,   75,  583]]                                  |
+-----------------------+-------------------------------------------------------+