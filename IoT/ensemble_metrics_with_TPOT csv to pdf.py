#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
CSV to PDF Report Generator for Enhanced Ensemble Learning Results

This script reads CSV files generated by the ensemble learning script and creates
PDF reports with the same structure as the original JPG visualizations.

Features:
- Reads individual device metrics CSV files
- Reads comprehensive comparison CSV files
- Creates PDF reports with tables matching the original JPG format
- Highlights TPOT vs ExtraTrees comparisons
- Generates summary reports
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import numpy as np
import glob
from datetime import datetime

# Configuration
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
INPUT_DIR = os.path.join(BASE_DIR, '..', 'Results', 'IoT', 'Enhanced_Ensemble_TPOT_ExtraTrees_Results')
OUTPUT_DIR = os.path.join(BASE_DIR, '..', 'Results', 'IoT', 'PDF_Reports')

# Ensure output directory exists
os.makedirs(OUTPUT_DIR, exist_ok=True)


def create_metrics_table_pdf(metrics_df, title, device_name, pdf_pages):
    """Create a PDF page with metrics table similar to the original JPG format."""
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.axis('tight')
    ax.axis('off')

    # Prepare table data
    cell_text = []
    for _, row in metrics_df.iterrows():
        formatted_row = [
            row['Model'],
            f"{row['F1 Score']:.4f}",
            f"{row['Training Time']:.2f}s"
        ]
        cell_text.append(formatted_row)

    # Create table
    table = ax.table(
        cellText=cell_text,
        colLabels=['Model', 'F1 Score', 'Training Time'],
        cellLoc='center',
        loc='center',
        colColours=['#f2f2f2'] * 3
    )

    # Format table
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.3, 2.0)

    # Highlight TPOT and ExtraTrees rows
    for i, (_, row) in enumerate(metrics_df.iterrows()):
        row_idx = i + 1  # +1 because of header
        if row['Model'] == 'TPOT (ExtraTrees)':
            for j in range(3):
                table[(row_idx, j)].set_facecolor('#e6f3ff')  # Blue for TPOT
        elif row['Model'] == 'ExtraTrees':
            for j in range(3):
                table[(row_idx, j)].set_facecolor('#f0fff0')  # Green for ExtraTrees

    # Add title
    plt.title(f'Performance Comparison: {title}\n(TPOT vs. ExtraTrees highlights AutoML impact)',
              fontsize=14, fontweight='bold', pad=20)

    # Add subtitle with analysis
    if 'TPOT (ExtraTrees)' in metrics_df['Model'].values and 'ExtraTrees' in metrics_df['Model'].values:
        tpot_f1 = metrics_df[metrics_df['Model'] == 'TPOT (ExtraTrees)']['F1 Score'].iloc[0]
        extratrees_f1 = metrics_df[metrics_df['Model'] == 'ExtraTrees']['F1 Score'].iloc[0]
        f1_diff = tpot_f1 - extratrees_f1

        subtitle = f"F1 Score Comparison: TPOT ({tpot_f1:.4f}) vs ExtraTrees ({extratrees_f1:.4f})\n"
        subtitle += f"Difference: {f1_diff:+.4f} "
        subtitle += "(AutoML hyperparameter optimization impact)"

        plt.figtext(0.5, 0.15, subtitle, ha='center', fontsize=10,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgray', alpha=0.5))

    plt.tight_layout()
    pdf_pages.savefig(fig, bbox_inches='tight')
    plt.close()


def create_comprehensive_comparison_pdf(comparison_df, device_name, pdf_pages):
    """Create a PDF page with comprehensive comparison table."""
    fig, ax = plt.subplots(figsize=(16, 10))
    ax.axis('tight')
    ax.axis('off')

    # Prepare table data
    cell_text = []
    for _, row in comparison_df.iterrows():
        if row['Model'] == 'AVERAGE':
            # Format average row differently
            formatted_row = [
                row['Model'],
                f"{row['Original F1 Score']:.4f}" if pd.notna(row['Original F1 Score']) else 'N/A',
                f"{row['BigFeat F1 Score']:.4f}" if pd.notna(row['BigFeat F1 Score']) else 'N/A',
                f"{row['F1 Diff (BigFeat - Original)']:+.4f}" if pd.notna(
                    row['F1 Diff (BigFeat - Original)']) else 'N/A',
                f"{row['Original Training Time']:.2f}s" if pd.notna(row['Original Training Time']) else 'N/A',
                f"{row['BigFeat Training Time']:.2f}s" if pd.notna(row['BigFeat Training Time']) else 'N/A',
                f"{row['Training Time Ratio (BigFeat/Original)']:.2f}x" if pd.notna(
                    row['Training Time Ratio (BigFeat/Original)']) else 'N/A',
                f"{row['F1 Diff (TPOT - ExtraTrees)']:+.4f}" if pd.notna(row['F1 Diff (TPOT - ExtraTrees)']) and row[
                    'F1 Diff (TPOT - ExtraTrees)'] != 0 else ""
            ]
        else:
            formatted_row = [
                row['Model'],
                f"{row['Original F1 Score']:.4f}",
                f"{row['BigFeat F1 Score']:.4f}",
                f"{row['F1 Diff (BigFeat - Original)']:+.4f}",
                f"{row['Original Training Time']:.2f}s",
                f"{row['BigFeat Training Time']:.2f}s",
                f"{row['Training Time Ratio (BigFeat/Original)']:.2f}x",
                f"{row['F1 Diff (TPOT - ExtraTrees)']:+.4f}" if row['Model'] == 'TPOT (ExtraTrees)' and pd.notna(
                    row['F1 Diff (TPOT - ExtraTrees)']) else ""
            ]
        cell_text.append(formatted_row)

    # Create table
    table = ax.table(
        cellText=cell_text,
        colLabels=['Model', 'Original F1 Score', 'BigFeat F1 Score', 'F1 Diff (BigFeat - Original)',
                   'Original Training Time', 'BigFeat Training Time', 'Training Time Ratio (BigFeat/Original)',
                   'F1 Diff (TPOT - ExtraTrees)'],
        cellLoc='center',
        loc='center',
        colColours=['#f2f2f2'] * 8
    )

    # Format table
    table.auto_set_font_size(False)
    table.set_fontsize(8)
    table.scale(1.5, 2.0)

    # Apply color coding
    for i, (_, row) in enumerate(comparison_df.iterrows()):
        row_idx = i + 1  # +1 because of header

        # Highlight TPOT and ExtraTrees rows
        if row['Model'] == 'TPOT (ExtraTrees)':
            for j in range(8):
                table[(row_idx, j)].set_facecolor('#e6f3ff')  # Blue for TPOT
        elif row['Model'] == 'ExtraTrees':
            for j in range(8):
                table[(row_idx, j)].set_facecolor('#f0fff0')  # Green for ExtraTrees
        elif row['Model'] == 'AVERAGE':
            for j in range(8):
                table[(row_idx, j)].set_facecolor('#ffffcc')  # Yellow for average

        # Color code difference columns
        if pd.notna(row['F1 Diff (BigFeat - Original)']):
            val = row['F1 Diff (BigFeat - Original)']
            if val > 0:
                table[(row_idx, 3)].set_facecolor('#d4f7d4')  # Green for positive diff
            elif val < 0:
                table[(row_idx, 3)].set_facecolor('#f7d4d4')  # Red for negative diff

        # Color code training time ratio
        if pd.notna(row['Training Time Ratio (BigFeat/Original)']):
            val = row['Training Time Ratio (BigFeat/Original)']
            if val < 1.0:
                table[(row_idx, 6)].set_facecolor('#d4f7d4')  # Green for faster
            elif val > 2.0:
                table[(row_idx, 6)].set_facecolor('#f7d4d4')  # Red for slower

        # Color code TPOT vs ExtraTrees difference
        if row['Model'] == 'TPOT (ExtraTrees)' and pd.notna(row['F1 Diff (TPOT - ExtraTrees)']):
            val = row['F1 Diff (TPOT - ExtraTrees)']
            if val > 0:
                table[(row_idx, 7)].set_facecolor('#d4f7d4')  # Green for positive diff
            elif val < 0:
                table[(row_idx, 7)].set_facecolor('#f7d4d4')  # Red for negative diff

    # Add title
    plt.title(f'{device_name} Comprehensive Comparison: Original vs BigFeat Features\n'
              f'Positive F1 Diff (BigFeat - Original) indicates feature engineering improvement\n'
              f'Positive F1 Diff (TPOT - ExtraTrees) indicates AutoML improvement over baseline',
              fontsize=12, fontweight='bold', pad=20)

    plt.tight_layout()
    pdf_pages.savefig(fig, bbox_inches='tight')
    plt.close()


def create_summary_pdf(overall_df, pdf_pages):
    """Create a PDF page with overall summary."""
    fig, ax = plt.subplots(figsize=(14, 10))
    ax.axis('tight')
    ax.axis('off')

    # Prepare summary statistics
    summary_text = []
    summary_text.append("ENHANCED ENSEMBLE LEARNING WITH TPOT AND BIGFEAT")
    summary_text.append("=" * 60)
    summary_text.append(f"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    summary_text.append("")

    if 'BigFeat_Available' in overall_df.columns:
        available_count = overall_df['BigFeat_Available'].sum()
        total_count = len(overall_df)
        summary_text.append(f"BigFeat Processing Statistics:")
        summary_text.append(f"Successfully processed: {available_count}/{total_count} devices")

        if available_count > 0:
            bigfeat_results = overall_df[overall_df['BigFeat_Available'] == True]
            avg_original_f1 = bigfeat_results['Best_Original_F1'].mean()
            avg_bigfeat_f1 = bigfeat_results['Best_BigFeat_F1'].mean()
            avg_improvement = bigfeat_results['F1_Improvement'].mean()

            summary_text.append(f"Average Original F1 Score: {avg_original_f1:.4f}")
            summary_text.append(f"Average BigFeat F1 Score: {avg_bigfeat_f1:.4f}")
            summary_text.append(f"Average F1 Improvement: {avg_improvement:+.4f}")

            positive_improvements = (bigfeat_results['F1_Improvement'] > 0).sum()
            summary_text.append(f"Devices with positive F1 improvement: {positive_improvements}/{available_count}")

            summary_text.append("")
            summary_text.append("Best Original Models Distribution:")
            original_model_counts = bigfeat_results['Best_Original_Model'].value_counts()
            for model, count in original_model_counts.items():
                summary_text.append(f"  {model}: {count}")

            summary_text.append("")
            summary_text.append("Best BigFeat Models Distribution:")
            bigfeat_model_counts = bigfeat_results['Best_BigFeat_Model'].value_counts()
            for model, count in bigfeat_model_counts.items():
                summary_text.append(f"  {model}: {count}")

    # Create summary table
    cell_text = []
    for _, row in overall_df.iterrows():
        formatted_row = [
            row['Device'],
            row['Best_Original_Model'],
            f"{row['Best_Original_F1']:.4f}",
            row.get('Best_BigFeat_Model', 'N/A'),
            f"{row['Best_BigFeat_F1']:.4f}" if pd.notna(row.get('Best_BigFeat_F1')) else 'N/A',
            f"{row['F1_Improvement']:+.4f}" if pd.notna(row.get('F1_Improvement')) else 'N/A',
            'Yes' if row.get('BigFeat_Available', False) else 'No'
        ]
        cell_text.append(formatted_row)

    # Create table
    table = ax.table(
        cellText=cell_text,
        colLabels=['Device', 'Best Original Model', 'Best Original F1', 'Best BigFeat Model',
                   'Best BigFeat F1', 'F1 Improvement', 'BigFeat Available'],
        cellLoc='center',
        loc='center',
        colColours=['#f2f2f2'] * 7
    )

    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1.4, 2.0)

    # Color code improvements
    for i, (_, row) in enumerate(overall_df.iterrows()):
        row_idx = i + 1
        if pd.notna(row.get('F1_Improvement')):
            val = row['F1_Improvement']
            if val > 0:
                table[(row_idx, 5)].set_facecolor('#d4f7d4')  # Green for positive
            elif val < 0:
                table[(row_idx, 5)].set_facecolor('#f7d4d4')  # Red for negative

        # Highlight availability
        if row.get('BigFeat_Available', False):
            table[(row_idx, 6)].set_facecolor('#d4f7d4')  # Green for available
        else:
            table[(row_idx, 6)].set_facecolor('#f7d4d4')  # Red for not available

    plt.title('Overall Summary: Enhanced Ensemble Learning Results',
              fontsize=14, fontweight='bold', pad=20)

    # Add summary text below table
    summary_str = '\n'.join(summary_text[:15])  # First 15 lines
    plt.figtext(0.1, 0.02, summary_str, fontsize=8, verticalalignment='bottom',
                bbox=dict(boxstyle="round,pad=0.5", facecolor='lightblue', alpha=0.3))

    plt.tight_layout()
    pdf_pages.savefig(fig, bbox_inches='tight')
    plt.close()


def process_device_reports():
    """Process individual device reports and create PDF versions."""
    print("Processing individual device reports...")

    # Find all device metrics CSV files
    metrics_pattern = os.path.join(INPUT_DIR, "*_original_*_metrics.csv")
    comparison_pattern = os.path.join(INPUT_DIR, "*_comprehensive_comparison.csv")

    metrics_files = glob.glob(metrics_pattern)
    comparison_files = glob.glob(comparison_pattern)

    print(f"Found {len(metrics_files)} metrics files")
    print(f"Found {len(comparison_files)} comparison files")

    # Process each device
    devices_processed = set()

    for metrics_file in metrics_files:
        try:
            # Extract device name from filename
            filename = os.path.basename(metrics_file)
            device_name = filename.split('_')[0]

            if device_name in devices_processed:
                continue

            print(f"Processing {device_name}...")

            # Create PDF for this device
            pdf_filename = os.path.join(OUTPUT_DIR, f"{device_name}_complete_report.pdf")

            with PdfPages(pdf_filename) as pdf_pages:
                # Page 1: Original features metrics
                if os.path.exists(metrics_file):
                    metrics_df = pd.read_csv(metrics_file)
                    create_metrics_table_pdf(
                        metrics_df,
                        f"{device_name} - Original Features",
                        device_name,
                        pdf_pages
                    )

                # Page 2: BigFeat features metrics (if available)
                bigfeat_metrics_file = os.path.join(INPUT_DIR,
                                                    f"{device_name}_bigfeat_with_tpot_extratrees_metrics.csv")
                if os.path.exists(bigfeat_metrics_file):
                    bigfeat_metrics_df = pd.read_csv(bigfeat_metrics_file)
                    create_metrics_table_pdf(
                        bigfeat_metrics_df,
                        f"{device_name} - With BigFeat Features",
                        device_name,
                        pdf_pages
                    )

                # Page 3: Comprehensive comparison (if available)
                comparison_file = os.path.join(INPUT_DIR, f"{device_name}_comprehensive_comparison.csv")
                if os.path.exists(comparison_file):
                    comparison_df = pd.read_csv(comparison_file)
                    create_comprehensive_comparison_pdf(comparison_df, device_name, pdf_pages)

            devices_processed.add(device_name)
            print(f"Created PDF report: {pdf_filename}")

        except Exception as e:
            print(f"Error processing {metrics_file}: {str(e)}")
            continue

    return len(devices_processed)


def create_summary_report():
    """Create overall summary PDF report."""
    print("Creating summary report...")

    # Look for overall summary CSV
    summary_file = os.path.join(INPUT_DIR, "overall_summary_extratrees.csv")

    if not os.path.exists(summary_file):
        print(f"Summary file not found: {summary_file}")
        return False

    try:
        overall_df = pd.read_csv(summary_file)

        pdf_filename = os.path.join(OUTPUT_DIR, "overall_summary_report.pdf")

        with PdfPages(pdf_filename) as pdf_pages:
            create_summary_pdf(overall_df, pdf_pages)

        print(f"Created summary PDF report: {pdf_filename}")
        return True

    except Exception as e:
        print(f"Error creating summary report: {str(e)}")
        return False


def main():
    """Main function to process all CSV files and create PDF reports."""
    print("=" * 80)
    print("CSV to PDF Report Generator")
    print("=" * 80)

    print(f"Input directory: {INPUT_DIR}")
    print(f"Output directory: {OUTPUT_DIR}")

    # Check if input directory exists
    if not os.path.exists(INPUT_DIR):
        print(f"ERROR: Input directory not found: {INPUT_DIR}")
        return

    # Process individual device reports
    devices_processed = process_device_reports()

    # Create summary report
    summary_created = create_summary_report()

    print("\n" + "=" * 80)
    print("PROCESSING COMPLETE")
    print("=" * 80)
    print(f"Devices processed: {devices_processed}")
    print(f"Summary report created: {'Yes' if summary_created else 'No'}")
    print(f"PDF reports saved to: {OUTPUT_DIR}")

    # List generated files
    pdf_files = glob.glob(os.path.join(OUTPUT_DIR, "*.pdf"))
    print(f"\nGenerated PDF files ({len(pdf_files)}):")
    for pdf_file in sorted(pdf_files):
        print(f"  {os.path.basename(pdf_file)}")


if __name__ == "__main__":
    main()